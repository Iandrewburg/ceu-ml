---
title: "CEU Machine Learning Tools - Session 1"
author: János Divényi
output: html_notebook
---

```{r}
library(tidyverse)
library(glmnet)
library(pls)  # for Principal-Component Regression
library(rpart)  # for Tree
library(ranger)  # for Random Forest
library(gbm)  # for Boosted Trees
theme_set(theme_minimal())
```

## Predict the demand for bike share using known tools

Our goal is to predict demand for bike share based on this Kaggle task.
Kaggle provides two data sets: a labelled train data and an unlabelled test data.
We have to use the train data to predict labels for the test data.
Kaggle won't give us the labels just a score we achieved on the test set.

Sample set

```{r load-data}
# kaggle data, the test set cannot be used for our test purposes
bike_data <- read_csv("../data/bike_sharing_demand/bike_sample.csv")
skimr::skim(bike_data)
```


```{r create-train-test-split}
n_obs <- nrow(bike_data)
test_share <- 0.2

set.seed(20220309)
test_indices <- sample(seq(n_obs), floor(test_share * n_obs))
bike_test <- slice(bike_data, test_indices)
bike_train <- slice(bike_data, -test_indices)
```


Kaggle will use the Root Mean Squared Log Error (RMSLE) to evaluate the predictions.
It has the advantage that one could interpret this as a relative error
(as the log difference is very close to the relative difference for small errors).

To avoid our RMSLE throwing an error, we have to ensure that our predictions are never negative.
In our case, it won't make any sense either, as demand cannot be negative.
Our models do not know that so we need to adjust negative predictions to zero.

```{r evaluation-function}
calculateRMSLE <- function(prediction, y_obs) {
    sqrt(mean((log(ifelse(prediction < 0, 0, prediction) + 1) - log(y_obs + 1))^2))
}
```


```{r benchmark-models}
avg <- mean(bike_train$count)
rmsle_results <- tibble(
    model = "Avg",
    train = calculateRMSLE(avg, bike_train$count),
    test = calculateRMSLE(avg, bike_test$count)
)
median <- median(bike_train$count)
rmsle_results <- add_row(rmsle_results,
    model = "Median",
    train = calculateRMSLE(median, bike_train$count),
    test = calculateRMSLE(median, bike_test$count)
)
rmsle_results
```


```{r group-averages}
group_averages <- lm(count ~ as.factor(season) + as.factor(holiday) + as.factor(workingday), data = bike_train)
rmsle_results <- add_row(rmsle_results,
    model = "Group-avg",
    train = calculateRMSLE(predict(group_averages, bike_train), bike_train$count),
    test = calculateRMSLE(predict(group_averages, bike_test), bike_test$count)
)
rmsle_results
```
```{r group-averages-with-weather}
group_averages_weather <- lm(
    count ~ as.factor(season) + as.factor(holiday) + as.factor(workingday) + as.factor(weather) + temp + atemp + humidity + windspeed,
    data = bike_train
)

rmsle_results <- add_row(rmsle_results,
    model = "Full linear",
    train = calculateRMSLE(predict(group_averages_weather), bike_train$count),
    test = calculateRMSLE(predict(group_averages_weather, bike_test), bike_test$count)
)
rmsle_results
```

```{r lasso}
createMatrixFeatures <- function(df) {
    model.matrix(
        ~ as.factor(season) + as.factor(holiday) + as.factor(workingday) + as.factor(weather) + temp + atemp + humidity + windspeed,
        data = df
    )
}
features <- createMatrixFeatures(bike_train)
outcome <- bike_train$count
lasso <- cv.glmnet(features,  outcome, alpha = 1)
lasso
```

```{r evaluating-lasso}
lasso_test_predictions <- predict(lasso, newx = createMatrixFeatures(bike_test), s = lasso$lambda.min)
rmsle_results <- add_row(rmsle_results,
    model = "CV LASSO",
    train = calculateRMSLE(predict(lasso, newx = features, s = lasso$lambda.min), bike_train$count),
    test = calculateRMSLE(lasso_test_predictions, bike_test$count)
)
rmsle_results
```

```{r pcr}
pcr_model <- pcr(outcome ~ features[, -1], scale = TRUE)
summary(pcr_model)
```

```{r evaluating-pcr}
rmsle_results <- add_row(rmsle_results,
    model = "PCR 8 comp",
    train = calculateRMSLE(as.numeric(predict(pcr_model, ncomp = 8)), bike_train$count),
    test = calculateRMSLE(as.numeric(predict(pcr_model, newdata = createMatrixFeatures(bike_test)[, -1], ncomp = 8)), bike_test$count)
)
rmsle_results
```


```{r tree}
tree_model <- rpart(
    count ~ as.factor(season) + as.factor(holiday) + as.factor(workingday) + as.factor(weather) + temp + atemp + humidity + windspeed,
    bike_train
)
rmsle_results <- add_row(rmsle_results,
    model = "Tree",
    train = calculateRMSLE(predict(tree_model), bike_train$count),
    test = calculateRMSLE(predict(tree_model, newdata = bike_test), bike_test$count)
)
rmsle_results
```


## Improve our models

### Diagnostics

```{r create-tibble-from-predictions}
bike_predictions <- select(bike_test, count) |>
    mutate(
        prediction_lm = predict(group_averages_weather, bike_test),
        prediction_lasso = lasso_test_predictions,
        prediction_tree = predict(tree_model, bike_test)
    )
```

```{r compare-observed-and-prediction-distributions}
bike_predictions |>
    pivot_longer(starts_with("prediction"), names_prefix = "prediction_") |>
    ggplot() +
    geom_density(aes(x = value, color = "Prediction"), size = 1) +
    geom_density(aes(x = count, color = "Observed"), size = 1) +
    facet_grid(~ name)
```


```{r plot-observed-vs-prediction}
bike_predictions |>
    pivot_longer(starts_with("prediction"), names_prefix = "prediction_") |>
    ggplot(aes(count, value)) +
    geom_point(alpha = 0.3, size = 2) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "firebrick") +
    facet_grid(~ name) +
    labs(x = "Observed", y = "Predicted")
```


### Stacking

```{r stacking}
stacked_prediction <- (bike_predictions$prediction_lm + bike_predictions$prediction_lasso + bike_predictions$prediction_tree) / 3
rmsle_results <- add_row(rmsle_results,
    model = "Simple stack",
    test = calculateRMSLE(stacked_prediction, bike_test$count)
)
rmsle_results
```

```{r look-at-small-counts}
filter(bike_train, count <= 20)
```


### Feature engineering: create new variables

```{r feature-engineering}
createAdditionalFeatures <- function(bike_data) {
    mutate(bike_data,
        month = as.factor(lubridate::month(datetime)),
        hour = as.factor(lubridate::hour(datetime)),
        weekday = as.factor(weekdays(datetime)),
        across(season:weather, as.factor),
        workingday = NULL,
        datetime = NULL,
        casual = NULL,
        registered = NULL
    )
}
bike_train_plus <- createAdditionalFeatures(bike_train)
bike_test_plus <- createAdditionalFeatures(bike_test)
```

```{r lm-on-feature-engineered-data}
linear_more_features <- lm(count ~ ., bike_train_plus)
rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng linear",
    train = calculateRMSLE(predict(linear_more_features), bike_train_plus$count),
    test = calculateRMSLE(predict(linear_more_features, bike_test_plus), bike_test_plus$count)
)
rmsle_results
```

```{r tree-on-feature-engineered-data}
tree_more_features <- rpart(count ~ ., bike_train_plus)
rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng tree",
    train = calculateRMSLE(predict(tree_more_features), bike_train_plus$count),
    test = calculateRMSLE(predict(tree_more_features, bike_test_plus), bike_test_plus$count)
)
rmsle_results
```


### Add more data

```{r load-full-data-set}
bike_full <- read_csv("../data/bike_sharing_demand/train.csv")
bike_train_full <- anti_join(bike_full, bike_test)
```


```{r lm-on-full-data}
full_linear_large_n <- lm(
    count ~ as.factor(season) + as.factor(holiday) + as.factor(workingday) + as.factor(weather) + temp + atemp + humidity + windspeed,
    data = bike_train_full
)
rmsle_results <- add_row(rmsle_results,
    model = "Full linear large n",
    train = calculateRMSLE(predict(full_linear_large_n), bike_train_full$count),
    test = calculateRMSLE(predict(full_linear_large_n, bike_test), bike_test$count)
)
rmsle_results
```



```{r lm-on-full-feature-engineered-data}
bike_train_full_plus <- createAdditionalFeatures(bike_train_full)
linear_plus_large_n <- lm(count ~ ., data = bike_train_full_plus)
rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng linear large n",
    train = calculateRMSLE(predict(linear_plus_large_n), bike_train_full$count),
    test = calculateRMSLE(predict(linear_plus_large_n, bike_test_plus), bike_test$count)
)
tail(rmsle_results)
```

```{r tree-on-full-feature-engineered-data}
tree_plus_large_n <- rpart(count ~ ., data = bike_train_full_plus)
rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng tree large n",
    train = calculateRMSLE(predict(tree_plus_large_n), bike_train_full$count),
    test = calculateRMSLE(predict(tree_plus_large_n, bike_test_plus), bike_test$count)
)
tail(rmsle_results)
```

### Train more flexible models

```{r rf-feature-engineered-data}
set.seed(20220309)
simple_rf <- ranger(count ~ ., bike_train_plus)

rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng RF",
    train = calculateRMSLE(simple_rf$predictions, bike_train$count),
    test = calculateRMSLE(predict(simple_rf, bike_test_plus)$predictions, bike_test$count)
)
tail(rmsle_results)
```

```{r rf-on-full-feature-engineered-data}
full_rf <- ranger(count ~ ., bike_train_full_plus)

rmsle_results <- add_row(rmsle_results,
    model = "Feature-eng RF large n",
    train = calculateRMSLE(full_rf$predictions, bike_train_full$count),
    test = calculateRMSLE(predict(full_rf, bike_test_plus)$predictions, bike_test$count)
)
tail(rmsle_results)
```


```{r gbm-feature-engineered-data}
gbm <- gbm(
    count ~ .,
    data = bike_train_plus,
    n.trees = 1000,
    shrinkage = 0.01,
    interaction.depth = 4
)
rmsle_results <- add_row(rmsle_results,
    model = "Gradient Boosting",
    train = calculateRMSLE(predict(gbm, bike_train_plus), bike_train$count),
    test = calculateRMSLE(predict(gbm, bike_test_plus), bike_test$count)
)
tail(rmsle_results)
```
```{r gbm-on-full-feature-engineered-data}
gbm_full <- gbm(
    count ~ .,
    data = bike_train_full_plus,
    n.trees = 1000,
    shrinkage = 0.01,
    interaction.depth = 4
)
rmsle_results <- add_row(rmsle_results,
    model = "Gradient Boosting large n",
    train = calculateRMSLE(predict(gbm_full, bike_train_full_plus), bike_train_full$count),
    test = calculateRMSLE(predict(gbm_full, bike_test_plus), bike_test$count)
)
tail(rmsle_results)
```

## Submit to Kaggle
```{r submit-to-kaggle}
kaggle_test <- read_csv("../data/bike_sharing_demand/test.csv")
full_train_rf <- ranger(count ~ ., createAdditionalFeatures(bike_full))
predictions <- predict(full_train_rf, createAdditionalFeatures(kaggle_test))$predictions
select(kaggle_test, datetime) |>
    mutate(count = predictions) |>
    write.csv("../data/bike_sharing_demand/kaggle_submission.csv", row.names = FALSE)
```

